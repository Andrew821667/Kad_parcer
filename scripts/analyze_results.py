#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ —Ä–∞—Å—á–µ—Ç —Ç–∞–π–º–ª–∞–π–Ω–∞ –¥–ª—è –ø–æ–ª–Ω–æ–π –±–∞–∑—ã.

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç:
- –°—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
- –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–ø–æ—Ä–æ–≤
- –°–≤—è–∑–∏ –º–µ–∂–¥—É –∞–∫—Ç–∞–º–∏
- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å—É–¥–∞–º –∏ —Å—É–¥—å—è–º

–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç:
- –í—Ä–µ–º—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Å–µ–π –±–∞–∑—ã (2020-2025)
- –û–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö
- –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ä–µ—Å—É—Ä—Å–∞–º
"""

import json
from pathlib import Path
from datetime import datetime, timedelta
from collections import Counter
from typing import Dict, List, Any


def load_results() -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞—Ä—Å–∏–Ω–≥–∞."""
    data_dir = Path("data")

    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–µ–ª–∞
    cases_file = data_dir / "january_2024_cases.json"
    if not cases_file.exists():
        print("‚ùå –§–∞–π–ª january_2024_cases.json –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞: python scripts/parse_all_january_2024.py")
        exit(1)

    cases = json.loads(cases_file.read_text(encoding="utf-8"))

    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ PDF
    pdf_metadata_file = data_dir / "january_2024_pdf_metadata.json"
    pdf_metadata = []
    if pdf_metadata_file.exists():
        pdf_metadata = json.loads(pdf_metadata_file.read_text(encoding="utf-8"))

    # –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats_file = data_dir / "january_2024_stats.json"
    stats = {}
    if stats_file.exists():
        stats = json.loads(stats_file.read_text(encoding="utf-8"))

    return {
        "cases": cases,
        "pdf_metadata": pdf_metadata,
        "stats": stats,
    }


def analyze_case_categories(cases: List[Dict]) -> Dict[str, int]:
    """–ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–µ–ª."""
    categories = Counter()

    for case in cases:
        # –ö–∞—Ç–µ–≥–æ—Ä–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ case_type –∏–ª–∏ –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –∏–∑ –¥—Ä—É–≥–∏—Ö –ø–æ–ª–µ–π
        category = case.get("case_type", "Unknown")
        categories[category] += 1

    return dict(categories)


def analyze_courts(cases: List[Dict]) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ —Å—É–¥–∞–º."""
    courts = Counter()
    court_details = {}

    for case in cases:
        court = case.get("court", "Unknown")
        courts[court] += 1

        if court not in court_details:
            court_details[court] = {
                "count": 0,
                "case_numbers": [],
            }

        court_details[court]["count"] += 1
        court_details[court]["case_numbers"].append(case.get("case_number"))

    return {
        "total_courts": len(courts),
        "distribution": dict(courts.most_common(20)),
        "details": court_details,
    }


def analyze_judges(cases: List[Dict]) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ —Å—É–¥—å—è–º."""
    judges = Counter()

    for case in cases:
        judge = case.get("judge", "Unknown")
        if judge and judge != "Unknown":
            judges[judge] += 1

    return {
        "total_judges": len(judges),
        "distribution": dict(judges.most_common(20)),
        "avg_cases_per_judge": sum(judges.values()) / len(judges) if judges else 0,
    }


def analyze_pdf_documents(pdf_metadata: List[Dict]) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö PDF –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
    if not pdf_metadata:
        return {}

    total_size = sum(doc["pdf_size"] for doc in pdf_metadata)
    doc_titles = Counter()

    for doc in pdf_metadata:
        title = doc.get("document_title", "Unknown")
        # –ò–∑–≤–ª–µ—á—å —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
        if "–†–µ—à–µ–Ω–∏–µ" in title or "—Ä–µ—à–µ–Ω–∏–µ" in title:
            doc_type = "–†–µ—à–µ–Ω–∏–µ"
        elif "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ" in title or "–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ" in title:
            doc_type = "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ"
        elif "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ" in title or "–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ" in title:
            doc_type = "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ"
        else:
            doc_type = "–î—Ä—É–≥–æ–µ"

        doc_titles[doc_type] += 1

    return {
        "total_pdfs": len(pdf_metadata),
        "total_size_mb": total_size / (1024 * 1024),
        "avg_size_kb": (total_size / len(pdf_metadata)) / 1024 if pdf_metadata else 0,
        "document_types": dict(doc_titles),
    }


def calculate_timeline(stats: Dict[str, Any], total_cases: int) -> Dict[str, Any]:
    """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å —Ç–∞–π–º–ª–∞–π–Ω –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Å–µ–π –±–∞–∑—ã."""

    parsing_stats = stats.get("parsing", {})
    avg_time_per_page = parsing_stats.get("avg_time_per_page", 5.0)  # —Å–µ–∫—É–Ω–¥—ã

    # –û—Ü–µ–Ω–∫–∏ –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö

    # 1 –º–µ—Å—è—Ü = ~1000 –¥–µ–ª (40 —Å—Ç—Ä–∞–Ω–∏—Ü)
    cases_per_month = total_cases

    # –ü–µ—Ä–∏–æ–¥: 2020-2025 = 6 –ª–µ—Ç = 72 –º–µ—Å—è—Ü–∞
    months_total = 72
    estimated_total_cases = cases_per_month * months_total

    # 21 –∞–ø–µ–ª–ª—è—Ü–∏–æ–Ω–Ω—ã–π —Å—É–¥
    courts_total = 21
    estimated_cases_all_courts = estimated_total_cases * courts_total

    # –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏

    # –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ 1 —Å—Ç—Ä–∞–Ω–∏—Ü—É (—Å —É—á–µ—Ç–æ–º –∑–∞–¥–µ—Ä–∂–µ–∫)
    time_per_page_sec = avg_time_per_page + 2  # –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å

    # 1 –º–µ—Å—è—Ü = 40 —Å—Ç—Ä–∞–Ω–∏—Ü
    pages_per_month = 40
    time_per_month_min = (time_per_page_sec * pages_per_month) / 60

    # –í—Å–µ –º–µ—Å—è—Ü—ã –æ–¥–Ω–æ–≥–æ —Å—É–¥–∞
    time_per_court_hours = (time_per_month_min * months_total) / 60

    # –í—Å–µ —Å—É–¥—ã (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ)
    time_all_courts_days = (time_per_court_hours * courts_total) / 24

    # –í—Å–µ —Å—É–¥—ã (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ, 5 –ø–æ—Ç–æ–∫–æ–≤)
    parallel_workers = 5
    time_all_courts_parallel_days = time_all_courts_days / parallel_workers

    return {
        "estimates": {
            "cases_per_month": cases_per_month,
            "total_months": months_total,
            "total_courts": courts_total,
            "estimated_total_cases_one_court": estimated_total_cases,
            "estimated_total_cases_all_courts": estimated_cases_all_courts,
        },
        "timing": {
            "avg_time_per_page_sec": time_per_page_sec,
            "time_per_month_min": time_per_month_min,
            "time_per_court_hours": time_per_court_hours,
            "time_all_courts_sequential_days": time_all_courts_days,
            "time_all_courts_parallel_days": time_all_courts_parallel_days,
        },
        "storage": {
            "avg_pdf_size_kb": 250,  # —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä PDF
            "estimated_pdfs_per_case": 2,  # –≤ —Å—Ä–µ–¥–Ω–µ–º 2 –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ –¥–µ–ª–æ
            "estimated_total_pdfs": estimated_cases_all_courts * 2,
            "estimated_storage_gb": (estimated_cases_all_courts * 2 * 250) / (1024 * 1024),
        },
        "recommendations": {
            "parallel_workers": parallel_workers,
            "batch_size": 10,  # —Å—Ç—Ä–∞–Ω–∏—Ü –∑–∞ —Ä–∞–∑
            "checkpoint_frequency": "–∫–∞–∂–¥—ã–µ 100 —Å—Ç—Ä–∞–Ω–∏—Ü",
            "estimated_timeline": f"{time_all_courts_parallel_days:.0f} –¥–Ω–µ–π ({time_all_courts_parallel_days/30:.1f} –º–µ—Å—è—Ü–µ–≤)",
        }
    }


def print_analysis_report(data: Dict[str, Any]):
    """–í—ã–≤–µ—Å—Ç–∏ –æ—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞."""

    cases = data["cases"]
    pdf_metadata = data["pdf_metadata"]
    stats = data["stats"]

    print("=" * 80)
    print("üìä –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ü–ê–†–°–ò–ù–ì–ê")
    print("=" * 80)
    print()

    # 1. –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("1Ô∏è‚É£  –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("-" * 80)
    print(f"   –í—Å–µ–≥–æ –¥–µ–ª: {len(cases)}")
    print(f"   PDF —Å–∫–∞—á–∞–Ω–æ: {len(pdf_metadata)}")
    print(f"   –í—Ä–µ–º—è –ø–∞—Ä—Å–∏–Ω–≥–∞: {stats.get('parsing', {}).get('parsing_time_sec', 0):.1f} —Å–µ–∫")
    print()

    # 2. –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–µ–ª
    print("2Ô∏è‚É£  –ö–ê–¢–ï–ì–û–†–ò–ò –î–ï–õ")
    print("-" * 80)
    categories = analyze_case_categories(cases)
    for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True)[:10]:
        print(f"   {cat}: {count}")
    print()

    # 3. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å—É–¥–∞–º
    print("3Ô∏è‚É£  –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –°–£–î–ê–ú")
    print("-" * 80)
    courts_analysis = analyze_courts(cases)
    print(f"   –í—Å–µ–≥–æ —Å—É–¥–æ–≤: {courts_analysis['total_courts']}")
    for court, count in list(courts_analysis['distribution'].items())[:5]:
        print(f"   {court}: {count}")
    print()

    # 4. –°—É–¥—å–∏
    print("4Ô∏è‚É£  –°–£–î–¨–ò")
    print("-" * 80)
    judges_analysis = analyze_judges(cases)
    print(f"   –í—Å–µ–≥–æ —Å—É–¥–µ–π: {judges_analysis['total_judges']}")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ –¥–µ–ª –Ω–∞ —Å—É–¥—å—é: {judges_analysis['avg_cases_per_judge']:.1f}")
    for judge, count in list(judges_analysis['distribution'].items())[:5]:
        print(f"   {judge}: {count}")
    print()

    # 5. PDF –¥–æ–∫—É–º–µ–Ω—Ç—ã
    print("5Ô∏è‚É£  PDF –î–û–ö–£–ú–ï–ù–¢–´")
    print("-" * 80)
    pdf_analysis = analyze_pdf_documents(pdf_metadata)
    if pdf_analysis:
        print(f"   –í—Å–µ–≥–æ PDF: {pdf_analysis['total_pdfs']}")
        print(f"   –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {pdf_analysis['total_size_mb']:.1f} MB")
        print(f"   –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä: {pdf_analysis['avg_size_kb']:.1f} KB")
        print()
        print("   –¢–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:")
        for doc_type, count in pdf_analysis['document_types'].items():
            print(f"      {doc_type}: {count}")
    print()

    # 6. –†–∞—Å—á–µ—Ç —Ç–∞–π–º–ª–∞–π–Ω–∞
    print("6Ô∏è‚É£  –†–ê–°–ß–ï–¢ –¢–ê–ô–ú–õ–ê–ô–ù–ê –î–õ–Ø –ü–û–õ–ù–û–ô –ë–ê–ó–´")
    print("-" * 80)
    timeline = calculate_timeline(stats, len(cases))

    print("   üìÖ –û—Ü–µ–Ω–∫–∏ –æ–±—ä–µ–º–∞:")
    print(f"      ‚Ä¢ –î–µ–ª –≤ –º–µ—Å—è—Ü (1 —Å—É–¥): {timeline['estimates']['cases_per_month']}")
    print(f"      ‚Ä¢ –í—Å–µ–≥–æ –º–µ—Å—è—Ü–µ–≤ (2020-2025): {timeline['estimates']['total_months']}")
    print(f"      ‚Ä¢ –í—Å–µ–≥–æ —Å—É–¥–æ–≤: {timeline['estimates']['total_courts']}")
    print(f"      ‚Ä¢ –í—Å–µ–≥–æ –¥–µ–ª (1 —Å—É–¥, 6 –ª–µ—Ç): {timeline['estimates']['estimated_total_cases_one_court']:,}")
    print(f"      ‚Ä¢ –í—Å–µ–≥–æ –¥–µ–ª (21 —Å—É–¥, 6 –ª–µ—Ç): {timeline['estimates']['estimated_total_cases_all_courts']:,}")
    print()

    print("   ‚è±Ô∏è  –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏:")
    print(f"      ‚Ä¢ –í—Ä–µ–º—è –Ω–∞ 1 —Å—Ç—Ä–∞–Ω–∏—Ü—É: {timeline['timing']['avg_time_per_page_sec']:.1f} —Å–µ–∫")
    print(f"      ‚Ä¢ –í—Ä–µ–º—è –Ω–∞ 1 –º–µ—Å—è—Ü: {timeline['timing']['time_per_month_min']:.1f} –º–∏–Ω")
    print(f"      ‚Ä¢ –í—Ä–µ–º—è –Ω–∞ 1 —Å—É–¥ (6 –ª–µ—Ç): {timeline['timing']['time_per_court_hours']:.1f} —á–∞—Å–æ–≤")
    print(f"      ‚Ä¢ –í—Ä–µ–º—è –Ω–∞ –≤—Å–µ (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ): {timeline['timing']['time_all_courts_sequential_days']:.0f} –¥–Ω–µ–π")
    print(f"      ‚Ä¢ –í—Ä–µ–º—è –Ω–∞ –≤—Å–µ (5 –ø–æ—Ç–æ–∫–æ–≤): {timeline['timing']['time_all_courts_parallel_days']:.0f} –¥–Ω–µ–π")
    print()

    print("   üíæ –û—Ü–µ–Ω–∫–∞ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞:")
    print(f"      ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä PDF: {timeline['storage']['avg_pdf_size_kb']} KB")
    print(f"      ‚Ä¢ PDF –Ω–∞ –¥–µ–ª–æ: {timeline['storage']['estimated_pdfs_per_case']}")
    print(f"      ‚Ä¢ –í—Å–µ–≥–æ PDF: {timeline['storage']['estimated_total_pdfs']:,}")
    print(f"      ‚Ä¢ –¢—Ä–µ–±—É–µ—Ç—Å—è –º–µ—Å—Ç–∞: {timeline['storage']['estimated_storage_gb']:.1f} GB")
    print()

    print("   üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print(f"      ‚Ä¢ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤: {timeline['recommendations']['parallel_workers']}")
    print(f"      ‚Ä¢ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {timeline['recommendations']['batch_size']} —Å—Ç—Ä–∞–Ω–∏—Ü")
    print(f"      ‚Ä¢ –ß–∞—Å—Ç–æ—Ç–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤: {timeline['recommendations']['checkpoint_frequency']}")
    print(f"      ‚Ä¢ ‚è∞ –ò–¢–û–ì–û–í–´–ô –¢–ê–ô–ú–õ–ê–ô–ù: {timeline['recommendations']['estimated_timeline']}")
    print()

    print("=" * 80)
    print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù")
    print("=" * 80)
    print()

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    analysis_file = Path("data/january_2024_analysis.json")
    analysis_file.write_text(
        json.dumps({
            "categories": categories,
            "courts": courts_analysis,
            "judges": judges_analysis,
            "pdfs": pdf_analysis,
            "timeline": timeline,
        }, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )
    print(f"üíæ –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {analysis_file}")


if __name__ == "__main__":
    print("üîç –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–∞—Ä—Å–∏–Ω–≥–∞...")
    print()

    data = load_results()
    print_analysis_report(data)
